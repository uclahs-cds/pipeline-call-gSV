class log_output_dir {
    static def check_permissions(path) {
        def filePath = new File(path)

        if (filePath.exists()) {
            if (filePath.canWrite()) {
                return
            }
            throw new Exception("${path} is not writable")
        }

        // Attempts to create directory if the path does not exist
        if (!filePath.mkdirs()) {
            throw new Exception("${path} does not exist and could not create")
        }
    }
}

methods {
    set_log_output_dir = {

        def patient
        def sample

        // assumes that patient and samples name are in the pipeline.config
        def reader = new FileReader(params.input_csv)
        reader.splitEachLine(',') { parts -> [patient = parts[0], sample = parts[1]] }

        def date = new Date().format('yyyyMMdd-HHmmss')
        if (params.sge_scheduler) {
            params.avere_prefix = '/data/data'
        } else {
            params.avere_prefix = '/hot/data'
        }

        if (params.blcds_registered_dataset == true) {
            if ("${params.dataset_id.length()}" != 11) {
                throw new Exception("Dataset id must be eleven characters long")
            }
            def disease = "${params.dataset_id.substring(0,4)}"
            params.output_log_dir = "${params.avere_prefix}/$disease/${params.dataset_id}/${patient}/${sample}/DNA/WGS/aligned/${params.reference_prefix}/log/call-gSV/$date"
            params.disease = "${disease}"
        } else {
            params.output_log_dir = "${params.output_dir}/$date/log/"
            params.disease = null
        }
        params.patient = "${patient}"
        params.sample = "${sample}"
        params.date = "${date}"
    }

    // Process specific scope
    set_process = {
        // Monitor process jobs with local (not slurm) executor
        process.executor = "local"
    }

    // Location of Nextflow temp directories
    set_env = {
        workDir = params.temp_dir
        NXF_WORK = params.temp_dir
        NXF_TEMP = params.temp_dir
        NXF_HOME = params.temp_dir
    }

    // Pipeline monitoring and metric files
    set_timeline = {
        timeline.enabled = true
        timeline.file = "${params.output_log_dir}/timeline.html"
    }
    set_trace = {
        trace.enabled = true
        trace.file = "${params.output_log_dir}/trace.txt"
    }
    set_report = {
        report.enabled = true
        report.file = "${params.output_log_dir}/report.html"
    }

    // Set up env, timeline, trace, and report above.
    setup = {
        methods.set_log_output_dir()
        log_output_dir.check_permissions(params.output_log_dir)
        methods.set_process()
        methods.set_env()
        methods.set_timeline()
        methods.set_trace()
        methods.set_report()
    }
}


methods.setup()

params {
    // Pipeline tool versions
    delly_version = '0.8.7'
    manta_version = '1.6.0'
    bcftools_version = '1.12'
    vcftools_version = '0.1.16'
    rtgtools_version = '3.12'
    validate_version = '2.1.0'
    sha512_version = '0.1'
}

// Enable docker
docker {
    enabled = true
    sudo = (params.sge_scheduler) ? true : false // Set to true if run on SGE

    // Pass user's UID/GID and group IDs to Docker
    uid_and_gid = "-u \$(id -u):\$(id -g)"
    all_group_ids = "\$(for i in `id --real --groups`; do echo -n \"--group-add=\$i \"; done)"

    runOptions = "${uid_and_gid} ${all_group_ids}"
}
